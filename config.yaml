# ===================================================================
#                    CONFIGURAZIONE PRINCIPALE
# ===================================================================

# --- Impostazioni Generali ---
seed: 42
device: "cuda"  # "cuda" o "cpu"

# --- Percorsi dei Dati ---
data:
  audio_root: "Adresso21/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/audio"
  transcripts_root: "transcripts"
  train_labels: "Adresso21/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/adresso-train-mmse-scores.csv"
  
  test_audio_root: "Adresso21/ADReSSo21-diagnosis-test/ADReSSo21/diagnosis/test-dist/audio"
  test_transcripts_root: "transcripts_test"
  test_task1_labels: "Adresso21/label_test_task1.csv"
  test_task2_labels: "Adresso21/label_test_task2.csv"
  features_root: "extracted_features"

# ===================================================================
#                   CONFIGURAZIONE TRASCRIZIONE (ASR)
# ===================================================================
# Modifica 'engine' per scegliere quale motore ASR usare.
# Lo script leggerà solo la sezione di configurazione corrispondente.
# ===================================================================

transcription:
  # CAMBIA QUI: "crisperwhisper", "nemo", o "whisperx"
  engine: "canary"
  overwrite: false

  # --- SEZIONE CRISPERWHISPER RIVISTA E CORRETTA ---
  crisperwhisper:
    # L'unico parametro che ci serve è l'ID del modello su Hugging Face
    model_id: "nyrahealth/CrisperWhisper" 
    batch_size: 16
    compute_type: "float16" # o "int8"
    
  # --- Impostazioni per NeMo ---
  nemo:
    model_name: "nvidia/parakeet-tdt-1.1b"
    batch_size: 2

  # --- Impostazioni per WhisperX ---
  whisperx:
    model_name: "nyrahealth/faster_ecapatdnn"
    batch_size: 16
    compute_type: "float16"
    language: "en"
    
## --- Configurazione Feature Manuali --
feature_extraction:
  # Opzioni: "egemaps", "compare", "mfcc_stats", "disvoice_prosody", "whisper_large_v3"
  feature_set: "whisper_large_v3" # <-- IMPOSTA QUESTO PER ESTRARRE GLI EMBEDDING
  overwrite: false

# --- NUOVA SEZIONE: Configurazione Estrazione Embedding ---
embedding_extraction:
  # Questo 'name' deve corrispondere a quello che metti in 'feature_set'
  name: "whisper_large_v3"
  
  # Puoi cambiarlo con "nyrahealth/CrisperWhisper" o altri modelli compatibili
  model_id: "openai/whisper-large-v3"
  
  # Il pooling "mean" è la scelta standard e più robusta
  pooling_strategy: "mean"
  #Numero di campioni per batch durante l'estrazione degli embedding
  batch_size: 16
# --- Configurazione Modelli Tabulari (per feature manuali) ---
tabular_model:
  # Opzioni: "svm", "xgboost", "lr" (Logistic Regression)
  name: "xgboost"
  
  # Griglie per GridSearchCV
  grids:
    svm:
      C: [0.1, 1, 10, 100]
      gamma: ["scale", "auto", 0.1, 0.01]
      kernel: ["rbf", "linear"]
    xgboost:
      n_estimators: [100, 200, 300]
      max_depth: [3, 5, 7]
      learning_rate: [0.01, 0.1, 0.2]
    lr:
      C: [0.01, 0.1, 1, 10]
      penalty: ["l1", "l2"]
      solver: ["liblinear"] # necessario per l1
# ===================================================================
#                     CONFIGURAZIONE ESPERIMENTO
# ===================================================================
# Questa sezione controlla le operazioni di training, predizione e valutazione
# lanciate con 'python scripts/run.py'.
# ===================================================================

# --- Task e Modello ---
task: "classification"    # "classification" o "regression"
modality: "audio"          # "text" o "audio"

# Modello di trascrizione da usare per l'addestramento del modello testuale.
# Deve corrispondere al nome della cartella creata da 'transcribe.py'.
# Esempio per Crisper: "Crisper_whisper-large-v3"
# Esempio per NeMo: "parakeet-tdt-0.6b-v2"
transcription_model_for_training: "parakeet-tdt-1.1b"

# --- Cross-Validation ---
k_folds: 10
output_dir: "outputs/bert_classification_CrisperWhisper" # Cartella dove salvare modelli e predizioni

# --- Parametri del Modello ---
model:
  text:
    name: "bert-large-uncased"
    max_length: 275
    dropout: 0.1

  audio:
    name: "ecapa-tdnn"
    pretrained: "speechbrain/spkrec-ecapa-voxceleb"
    sample_rate: 16000
    trainable_encoder: true 
    dropout: 0.1

# --- Parametri di Addestramento ---
training:
  epochs: 15
  batch_size: 16
  learning_rate: 1.0e-3
  weight_decay: 0.01
  warmup_ratio: 0.1
  early_stopping_patience: 5
  eval_metric: "f1" # Per classificazione: "accuracy" o "f1". Per regressione: "rmse".

score_generation_models:
  - output_dir: "outputs/bert_classification_large-v3"
  - output_dir: "outputs/bert_classification_parakeet-tdt-1.1b"
