{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36b3762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== TRAIN | Statistiche per testo (WhisperX_nyrahealth) ==\n",
      "CN: n=79 | [UH] mean=2.241 std=2.371 | [UM] mean=1.354 std=1.783\n",
      "AD: n=87 | [UH] mean=2.690 std=3.258 | [UM] mean=0.483 std=1.088\n",
      "\n",
      "== TRAIN | Totali per diagnosi ==\n",
      "CN: UH=177  UM=107  (UH+UM=284)\n",
      "AD: UH=234  UM=42  (UH+UM=276)\n",
      "\n",
      "== TEST | Statistiche per testo (WhisperX_nyrahealth) ==\n",
      "CN: n=36 | [UH] mean=2.528 std=3.308 | [UM] mean=0.750 std=1.251\n",
      "AD: n=35 | [UH] mean=2.000 std=2.288 | [UM] mean=0.200 std=0.473\n",
      "\n",
      "== TEST | Totali per diagnosi ==\n",
      "CN: UH=91  UM=27  (UH+UM=118)\n",
      "AD: UH=70  UM=7  (UH+UM=77)\n",
      "\n",
      "== COMBINATI (train+test) | Totali per diagnosi ==\n",
      "CN: UH=268  UM=134  (UH+UM=402)\n",
      "AD: UH=304  UM=49  (UH+UM=353)\n"
     ]
    }
   ],
   "source": [
    "# Notebook code: conta [UH]/[UM] SOLO per i transcript di WhisperX_nyrahealth\n",
    "# e stampa statistiche split per diagnosi (AD vs CN) separando TRAIN e TEST.\n",
    "# Niente CSV: solo print.\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --------------- CONFIG ---------------\n",
    "TRANSCRIPT_DIRS = [\n",
    "    Path(\"transcripts/WhisperX_nyrahealth\"),\n",
    "    Path(\"transcripts_test/WhisperX_nyrahealth\"),\n",
    "]\n",
    "TRAIN_LABELS = Path(\"Adresso21/ADReSSo21-diagnosis-train/ADReSSo21/diagnosis/train/adresso-train-mmse-scores.csv\")\n",
    "TEST_LABELS  = Path(\"Adresso21/label_test_task1.csv\")  # etichette AD/CN del test\n",
    "# --------------------------------------\n",
    "\n",
    "# ---- carica e normalizza label -> (ID, Dx, subset) ----\n",
    "def _normalize_labels_df(df: pd.DataFrame, subset: str) -> pd.DataFrame:\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    # ID\n",
    "    id_col = None\n",
    "    for cand in [\"id\", \"adressfname\", \"adressfilename\", \"filename\", \"name\"]:\n",
    "        if cand in cols: id_col = cols[cand]; break\n",
    "    if id_col is None:\n",
    "        raise ValueError(f\"Colonna ID non trovata nelle label: {df.columns.tolist()}\")\n",
    "    # Dx\n",
    "    dx_col = None\n",
    "    for cand in [\"dx\", \"diagnosis\", \"label\", \"class\"]:\n",
    "        if cand in cols: dx_col = cols[cand]; break\n",
    "    if dx_col is None:\n",
    "        raise ValueError(f\"Colonna diagnosi non trovata nelle label: {df.columns.tolist()}\")\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"ID\": df[id_col].astype(str).str.replace(r\"\\.wav$\", \"\", regex=True).str.lower(),\n",
    "        \"Dx_raw\": df[dx_col].astype(str),\n",
    "    })\n",
    "    map_dict = {\n",
    "        \"ad\":\"AD\",\"cn\":\"CN\",\"probablead\":\"AD\",\"control\":\"CN\",\n",
    "        \"AD\":\"AD\",\"CN\":\"CN\",\"ProbableAD\":\"AD\",\"Control\":\"CN\",\n",
    "    }\n",
    "    out[\"Dx\"] = out[\"Dx_raw\"].str.strip().map(lambda x: map_dict.get(x, map_dict.get(x.lower(), x)))\n",
    "    out[\"subset\"] = subset\n",
    "    return out[[\"ID\",\"Dx\",\"subset\"]]\n",
    "\n",
    "label_frames = []\n",
    "if TRAIN_LABELS.exists():\n",
    "    label_frames.append(_normalize_labels_df(pd.read_csv(TRAIN_LABELS), \"train\"))\n",
    "if TEST_LABELS.exists():\n",
    "    label_frames.append(_normalize_labels_df(pd.read_csv(TEST_LABELS), \"test\"))\n",
    "if not label_frames:\n",
    "    raise FileNotFoundError(\"File di label non trovati. Controlla TRAIN_LABELS e TEST_LABELS.\")\n",
    "\n",
    "labels = pd.concat(label_frames, ignore_index=True).drop_duplicates(subset=[\"ID\",\"subset\"])\n",
    "\n",
    "# ---- regex per [UH]/[UM] ----\n",
    "pat_UH = re.compile(r\"\\[UH\\]\", re.IGNORECASE)\n",
    "pat_UM = re.compile(r\"\\[UM\\]\", re.IGNORECASE)\n",
    "\n",
    "# ---- scansione SOLO dei transcript WhisperX_nyrahealth ----\n",
    "rows = []\n",
    "for base in TRANSCRIPT_DIRS:\n",
    "    if not base.exists():\n",
    "        continue\n",
    "    subset = \"test\" if \"transcripts_test\" in base.parts else \"train\"\n",
    "    for p in base.rglob(\"*.txt\"):\n",
    "        file_id = p.stem.lower()\n",
    "        try:\n",
    "            txt = p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                txt = f.read()\n",
    "        uh = len(pat_UH.findall(txt))\n",
    "        um = len(pat_UM.findall(txt))\n",
    "        rows.append({\"subset\": subset, \"file_id\": file_id, \"UH\": uh, \"UM\": um})\n",
    "\n",
    "if not rows:\n",
    "    raise RuntimeError(\"Nessun .txt trovato sotto transcripts*/WhisperX_nyrahealth.\")\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# ---- join con le label e filtro AD/CN ----\n",
    "df_lab = df.merge(labels, left_on=[\"file_id\",\"subset\"], right_on=[\"ID\",\"subset\"], how=\"left\")\n",
    "df_lab = df_lab[df_lab[\"Dx\"].isin([\"AD\",\"CN\"])].copy()\n",
    "\n",
    "# ---- stampe: mean/std per testo e totali, split per subset & Dx ----\n",
    "def _print_stats(sub, subset_name):\n",
    "    print(f\"== {subset_name.upper()} | Statistiche per testo (WhisperX_nyrahealth) ==\")\n",
    "    for dx in [\"CN\",\"AD\"]:\n",
    "        part = sub[sub[\"Dx\"] == dx]\n",
    "        if part.empty:\n",
    "            print(f\"{dx}: nessun file.\")\n",
    "            continue\n",
    "        n = len(part)\n",
    "        mean_uh, std_uh = part[\"UH\"].mean(), part[\"UH\"].std(ddof=1) if n>1 else 0.0\n",
    "        mean_um, std_um = part[\"UM\"].mean(), part[\"UM\"].std(ddof=1) if n>1 else 0.0\n",
    "        print(f\"{dx}: n={n} | [UH] mean={mean_uh:.3f} std={std_uh:.3f} | [UM] mean={mean_um:.3f} std={std_um:.3f}\")\n",
    "    print()\n",
    "    print(f\"== {subset_name.upper()} | Totali per diagnosi ==\")\n",
    "    agg = sub.groupby(\"Dx\")[[\"UH\",\"UM\"]].sum()\n",
    "    for dx in [\"CN\",\"AD\"]:\n",
    "        if dx in agg.index:\n",
    "            uh, um = int(agg.loc[dx,\"UH\"]), int(agg.loc[dx,\"UM\"])\n",
    "            print(f\"{dx}: UH={uh}  UM={um}  (UH+UM={uh+um})\")\n",
    "    print()\n",
    "\n",
    "_print_stats(df_lab[df_lab[\"subset\"]==\"train\"], \"train\")\n",
    "_print_stats(df_lab[df_lab[\"subset\"]==\"test\"],  \"test\")\n",
    "\n",
    "# (opzionale) totali combinati train+test\n",
    "comb = df_lab.groupby(\"Dx\")[[\"UH\",\"UM\"]].sum()\n",
    "print(\"== COMBINATI (train+test) | Totali per diagnosi ==\")\n",
    "for dx in [\"CN\",\"AD\"]:\n",
    "    if dx in comb.index:\n",
    "        uh, um = int(comb.loc[dx,\"UH\"]), int(comb.loc[dx,\"UM\"])\n",
    "        print(f\"{dx}: UH={uh}  UM={um}  (UH+UM={uh+um})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
